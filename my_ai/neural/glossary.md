# Glossary

## B

* ***bias***  

## C

* ***cost function***

## F

* ***feedforward*** neural networks, the output from one layer is used has the input for the next layer. There are no loops in the network - information is always fed forward, never fed back.

## G

* ***gradient descent*** learning algorithm for neural networks

## H

* ***hidden layer***

## I

* ***input layer***
* ***input neurons***
* ***input perceptron(s)***

## L

* ***layer, first***
* ***layer, input***
* ***learning algorithms*** automatically tune the weights and biases of a network of artificial neurons
<<<<<<< Updated upstream
* ***logistic function***, same than the sigmoid function, an alias, a synonym
=======
* ***logistic function***, same than the sigmoid function, an alias, a synonym.
* ***loss function***, alias for cost function

## M

* ***multilayer perceptrons, MLP***

## O

* ***objective function***, alias for cost function
* ***output layer***
* ***output neurons***
>>>>>>> Stashed changes

## P

* ***perceptron*** artificial neuron

## R

* **recurrent neural networks***

## S

* ***segmentation problem***
* ***sigmoid function***
* ***sigmoid neuron*** artificial neuron
* ***stocastic gradient descent*** learning algorithm for neural networks

## T

* ***threshold***
