{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "dc6deececbf183c8613558516fc6e4182faf0badcaf931a5540c4f112efb8318"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hypothesis and Inference\n",
    "\n",
    "*Null hypothesis, H<sub>0</sub>*\n",
    "\n",
    "*type 1 error* (“false positive”)\n",
    "\n",
    "*type 2 error* (“false negative”)\n",
    "\n",
    "*significance* of a test, how willing we are to make a *type 1 error* (“false positive”), in which we reject H<sub>0</sub> even though it’s true.\n",
    "\n",
    "*power* of a test, which is the probability of not making a *type 2 error*, in which we fail to reject H<sub>0</sub> even though it’s false."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports, Python core\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "# imports, this project\n",
    "from ch07_hypothesis_and_inference import normal_approximation_to_binomial\n",
    "from ch07_hypothesis_and_inference import normal_probability_between\n",
    "from ch07_hypothesis_and_inference import normal_two_sided_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Hypothesis Testing\n",
    "\n",
    "Test whether a certain hypothesis is likely to be true.\n",
    "\n",
    "In the classical setup, we have a ***null hypothesis*** *H<sub>0</sub>* that represents some default position, and some alternative hypothesis *H<sub>1</sub>* that we’d like to compare it with. We use statistics to decide whether we can reject *H<sub>0</sub>* as false or not."
   ]
  },
  {
   "source": [
    "## Example: Flipping a Coin\n",
    "\n",
    "Imagine we have a coin and we want to test whether it’s fair. We’ll make the assumption that the coin has some probability *p* of landing heads, and so our null hypothesis is that the coin is fair, that is, that *p* = 0.5. We’ll test this against the alternative hypothesis *p* ≠ 0.5.\n",
    "\n",
    "***\n",
    "***Default position/null hypothesis, H<sub>0</sub>: *p* = 0.5***\n",
    "\n",
    "***Alternative position, H<sub>1</sub>: *p* ≠ 0.5***\n",
    "***\n",
    "\n",
    "Our test will involve flipping the coin some number n times and counting the number of heads X.\n",
    "\n",
    "In particular, let’s say that we choose to flip the coin n = 1000 times. If our hypothesis of fairness is true, X should be distributed approximately normally with mean 500 and standard deviation 15.8:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "flipping a coin 1000 times, with a p=0.5 results in\nmean of: 500.0\nsigma/standard deviation of: 15.81\n"
     ]
    }
   ],
   "source": [
    "# In particular, let’s say that we choose to flip the coin n = 1000 times. If our hypothesis\n",
    "# of fairness is true, X should be distributed approximately normally with mean 500 and\n",
    "# standard deviation 15.8:\n",
    "\n",
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)     # (500, 15.8)\n",
    "print('flipping a coin 1000 times, with a p=0.5 results in')\n",
    "print('mean of:', round(mu_0, 2))\n",
    "print('sigma/standard deviation of:', round(sigma_0, 2))"
   ]
  },
  {
   "source": [
    "### type-1 error, (“false positive”); significance\n",
    "\n",
    "We need to make a decision about ***significance***, how willing we are to make a *type 1 error* (“false positive”), in which we reject *H<sub>0</sub>* even though it’s true. For reasons lost to # the annals of history, this willingness is often set at 5% or 1%. Let’s choose 5%.\n",
    "\n",
    "Assuming p really equals 0.5 (i.e., *H<sub>0</sub>* is true), there is just a 5% chance we observe an X that lies outside this interval, which is the exact significance we wanted. Said differently, if *H<sub>0</sub>* is true, then, approximately 19 times out of 20, this test will give the correct result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We will reject H0 if X falls outside the bounds: 469.01 < X < 530.99\n"
     ]
    }
   ],
   "source": [
    "# Consider the test that rejects H0 if X falls outside the bounds given by:\n",
    "\n",
    "lower, uppper = normal_two_sided_bounds(0.95, mu_0, sigma_0)    # (469, 531)\n",
    "print('We will reject H0 if X falls outside the bounds:', round(lower, 2), '< X <',round(uppper, 2))"
   ]
  },
  {
   "source": [
    "### type 2 error (“false negative”), in which we fail to reject *H<sub>0</sub>* even though it’s false; power\n",
    "\n",
    "We are also often interested in the ***power*** of a test, which is the probability of not making a *type 2 error* (\"false negative\"), in which we fail to reject *H<sub>0</sub>* even though it’s false. In order to measure this, we have to specify what exactly *H<sub>0</sub>* being false means. (Knowing merely that p is not 0.5 doesn’t give you a ton of information about the distribution of X). In particular, let’s check what happens if p is really 0.55, so that the coin is slightly biased toward heads.\n",
    "\n",
    "In that case, we can calculate the power of the test with:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'low' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f3a87daeaecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 95% bounds based on assumption p is 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_two_sided_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"high and low 95% bounds for normal distribution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"and\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# actual mu and sigma based on p = 0.55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'low' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 95% bounds based on assumption p is 0.5\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "print(\"high and low 95% bounds for normal distribution\", hi, \"and\", lo)\n",
    "\n",
    "# actual mu and sigma based on p = 0.55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
    "\n",
    "# a type 2 error means we fail to reject the null hypothesis\n",
    "# which will happen when X is still in our original interval\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability      # 0.887\n",
    "print(\"power is:\", round(power, 3))"
   ]
  },
  {
   "source": [
    "## Confidence Intervals"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}