# About this folder

Notes from online book *[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)* by Michael Nielsen.

Book code is in Github, [mnielsen/neural-networks-and-deep-learning](https://github.com/mnielsen/neural-networks-and-deep-learning)

<https://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking>

## Glossary

* activation
* backpropagation
* bias
* bias vector
* cost function
* cross-entropy cost function, *C = -1/n Σ<sub>x</sub> [y ln a + (1 - y) ln(1-a)]*
* cuadratic cost
* elementwise
* error ð<sup>l</sup><sub>j</sub> in the j<sup>th</sup> neuron in the l<sup>th</sup> layer
* gradient descent
* Hadamard product, elementwise product of two vectors; (v, v) -> v:
* hyper-parameters
* loss function
* overfitting
* regularization L1
* regularization L2
* regularization dropout
* regularization, artificial expansion of the training data
* Schur product, see Hadamar product
* σ, sigmoid or step
* softmax
* vectorization
* weight
* weighted input, *z<sup>l</sup><sub>j</sub>* in the j<sup>th</sup> neuron in the l<sup>th</sup> layer
Σσ
